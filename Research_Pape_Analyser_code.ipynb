{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YptvsrXW4rUR"
   },
   "source": [
    "INSTALLING ALL THE REQUIRED PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLwbS1A5Js6G"
   },
   "outputs": [],
   "source": [
    "!pip install google-auth\n",
    "!pip install google-auth-oauthlib\n",
    "!pip install google-auth-httplib2\n",
    "!pip install google-api-python-client\n",
    "!pip install pathway\n",
    "!pip install sentence-transformers\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install PyPDF2\n",
    "!pip install tensorflow\n",
    "!pip install imbalanced-learn\n",
    "!pip install pymupdf\n",
    "!pip install higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAYg1CMq5Syz"
   },
   "source": [
    "IMPORTING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SN3KF9naKwD_"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import fitz\n",
    "import spacy\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7u0Zkhox5c1y"
   },
   "source": [
    "MOUNTING DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itMl6zIxYFN1"
   },
   "outputs": [],
   "source": [
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpNvasDQ5m9b"
   },
   "source": [
    "INTIALIZING THE PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c8xvDNPLPCm"
   },
   "outputs": [],
   "source": [
    "# Define folder paths based on your Google Drive structure\n",
    "base_path = '/content/drive/MyDrive/Colab Notebooks/Research_paper'  # base path\n",
    "references_path = os.path.join(base_path, 'Reference')  # Path to references folder\n",
    "papers_path = os.path.join(base_path, 'Papers')  # Path to papers folder\n",
    "\n",
    "# Verify folder structure and files\n",
    "papers_files = os.listdir(papers_path)  # List all papers in the papers folder\n",
    "references_files = os.listdir(references_path)  # List all references in the references folder\n",
    "\n",
    "# Display a few files from each folder to verify\n",
    "papers_files[:5], references_files[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQDU-_H5LHsR"
   },
   "source": [
    "-------------------------------------**TASK 1**-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZexQSEb-wJiF"
   },
   "source": [
    "MASTER FEATURE EXTRACTION AND FLATTENINF IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_e0t5y-9wCri"
   },
   "outputs": [],
   "source": [
    "# 1. Text Extraction from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# 2. Section-wise Segmentation\n",
    "def segment_text(text):\n",
    "    # Basic segmentation based on common section headings in research papers\n",
    "    sections = {\n",
    "        \"abstract\": \"\",\n",
    "        \"introduction\": \"\",\n",
    "        \"methodology\": \"\",\n",
    "        \"results\": \"\",\n",
    "        \"conclusion\": \"\"\n",
    "    }\n",
    "    current_section = None\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip().lower()\n",
    "        if \"abstract\" in line:\n",
    "            current_section = \"abstract\"\n",
    "        elif \"introduction\" in line:\n",
    "            current_section = \"introduction\"\n",
    "        elif \"methodology\" in line or \"materials and methods\" in line:\n",
    "            current_section = \"methodology\"\n",
    "        elif \"results\" in line:\n",
    "            current_section = \"results\"\n",
    "        elif \"conclusion\" in line:\n",
    "            current_section = \"conclusion\"\n",
    "        if current_section:\n",
    "            sections[current_section] += line + \" \"\n",
    "    return sections\n",
    "\n",
    "# 3. TF-IDF Features\n",
    "def extract_tfidf_features(texts, max_features=5000):\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=max_features)\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    return tfidf_matrix, vectorizer.get_feature_names_out()\n",
    "\n",
    "# 4. Semantic Features using BERT\n",
    "def extract_bert_embeddings(text, model_name=\"bert-base-uncased\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    # Use the mean of the last hidden states as the embedding\n",
    "    embeddings = torch.mean(outputs.last_hidden_state, dim=1)\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# 5. Sentence Coherence Features\n",
    "def compute_sentence_coherence(text):\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    sentences = text.split(\".\")\n",
    "    embeddings = model.encode(sentences)\n",
    "    coherence_score = np.mean([\n",
    "        np.dot(embeddings[i], embeddings[i+1]) /\n",
    "        (np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[i+1]))\n",
    "        for i in range(len(embeddings) - 1)\n",
    "    ])\n",
    "    return coherence_score\n",
    "\n",
    "# 6. Numerical Feature Extraction (e.g., Metrics Validation)\n",
    "\n",
    "def extract_numerical_features(text):\n",
    "    \"\"\"\n",
    "    Extract numerical features from the given text.\n",
    "    This function extracts all numbers from the text and returns a dictionary of numerical features.\n",
    "    \"\"\"\n",
    "    # Extract all numbers from the text\n",
    "    numbers = re.findall(r\"\\b\\d+(\\.\\d+)?\\b\", text)\n",
    "\n",
    "    # Filter out any empty strings or non-numeric values\n",
    "    numbers = [float(num) for num in numbers if num.strip() != \"\"]\n",
    "\n",
    "    # If no numbers are found, return default values\n",
    "    if not numbers:\n",
    "        return {\"mean\": None, \"std\": None, \"max\": None, \"min\": None, \"count\": 0}\n",
    "\n",
    "    # Calculate and return basic numerical features\n",
    "    return {\n",
    "        \"mean\": sum(numbers) / len(numbers),\n",
    "        \"std\": (sum((x - sum(numbers) / len(numbers))**2 for x in numbers) / len(numbers))**0.5,\n",
    "        \"max\": max(numbers),\n",
    "        \"min\": min(numbers),\n",
    "        \"count\": len(numbers)  # Count of numbers extracted\n",
    "    }\n",
    "\n",
    "# 7. Logical Consistency Check\n",
    "def check_logical_consistency(methodology, results):\n",
    "    # Compare sentences from methodology and results for semantic alignment\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    methodology_embedding = model.encode([methodology])\n",
    "    results_embedding = model.encode([results])\n",
    "    similarity = np.dot(methodology_embedding, results_embedding.T) / (\n",
    "        np.linalg.norm(methodology_embedding) * np.linalg.norm(results_embedding)\n",
    "    )\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Main Feature Extraction Pipeline\n",
    "def extract_features(pdf_path):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    sections = segment_text(text)\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # TF-IDF Features\n",
    "    features[\"tfidf\"], feature_names = extract_tfidf_features([text])\n",
    "\n",
    "    # BERT Embeddings\n",
    "    features[\"bert_abstract\"] = extract_bert_embeddings(sections.get(\"abstract\", \"\"))\n",
    "    features[\"bert_methodology\"] = extract_bert_embeddings(sections.get(\"methodology\", \"\"))\n",
    "    features[\"bert_results\"] = extract_bert_embeddings(sections.get(\"results\", \"\"))\n",
    "\n",
    "    # Sentence Coherence\n",
    "    features[\"coherence_abstract\"] = compute_sentence_coherence(sections.get(\"abstract\", \"\"))\n",
    "    features[\"coherence_methodology\"] = compute_sentence_coherence(sections.get(\"methodology\", \"\"))\n",
    "\n",
    "    # Numerical Features\n",
    "    features[\"numerical_abstract\"] = extract_numerical_features(sections.get(\"abstract\", \"\"))\n",
    "    features[\"numerical_results\"] = extract_numerical_features(sections.get(\"results\", \"\"))\n",
    "\n",
    "    # Logical Consistency\n",
    "    features[\"logical_consistency\"] = check_logical_consistency(\n",
    "        sections.get(\"methodology\", \"\"), sections.get(\"results\", \"\")\n",
    "    )\n",
    "\n",
    "    return features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sT1lmXY4xjos"
   },
   "outputs": [],
   "source": [
    "def flatten_features(features_dict):\n",
    "    \"\"\"\n",
    "    Flatten the dictionary into a list of features.\n",
    "    \"\"\"\n",
    "    flattened = []\n",
    "\n",
    "    # Add coherence features\n",
    "    flattened.append(features_dict.get('coherence_abstract', None))\n",
    "    flattened.append(features_dict.get('coherence_methodology', None))\n",
    "    flattened.append(features_dict.get('logical_consistency', None))\n",
    "\n",
    "    # Add numerical features for abstract and results, using .get() to avoid KeyError\n",
    "    flattened.extend([\n",
    "        features_dict.get('numerical_abstract', {}).get('mean', None),\n",
    "        features_dict.get('numerical_abstract', {}).get('max', None),\n",
    "        features_dict.get('numerical_abstract', {}).get('min', None),\n",
    "        features_dict.get('numerical_abstract', {}).get('count', 0),  # Default to 0 if 'count' is missing\n",
    "\n",
    "        features_dict.get('numerical_results', {}).get('mean', None),\n",
    "        features_dict.get('numerical_results', {}).get('max', None),\n",
    "        features_dict.get('numerical_results', {}).get('min', None),\n",
    "        features_dict.get('numerical_results', {}).get('count', 0)  # Default to 0 if 'count' is missing\n",
    "    ])\n",
    "\n",
    "    # Add BERT embeddings, flattened to 1D array\n",
    "    flattened.extend(features_dict.get('bert_abstract', {}).flatten() if 'bert_abstract' in features_dict else [])\n",
    "    flattened.extend(features_dict.get('bert_methodology', {}).flatten() if 'bert_methodology' in features_dict else [])\n",
    "    flattened.extend(features_dict.get('bert_results', {}).flatten() if 'bert_results' in features_dict else [])\n",
    "\n",
    "    return flattened\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDWToDk4jjus"
   },
   "source": [
    "EXTARCTING PAPERS TO BE PREDICTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5w1JH1ShqQxO"
   },
   "outputs": [],
   "source": [
    "# Extract text and paper IDs from all papers\n",
    "papers_data = []\n",
    "c = 0 #for counting file\n",
    "for paper_file in papers_files:\n",
    "    c += 1\n",
    "    print(f\"Processing paper {c}: {paper_file}\")\n",
    "    paper_path = os.path.join(papers_path, paper_file)\n",
    "\n",
    "    if paper_file.endswith('.pdf'):  # Process only PDF files\n",
    "        # Extract paper ID by removing '.pdf'\n",
    "        paper_id = paper_file.replace('.pdf', '')\n",
    "\n",
    "        # Extract features and flatten\n",
    "        features_dict = extract_features(paper_path)  # Extract features from the PDF\n",
    "        flattened_features = flatten_features(features_dict)\n",
    "        flattened_features = np.array(flattened_features, dtype=np.float32)\n",
    "\n",
    "        # Replace NaN values with 0\n",
    "        if np.any(np.isnan(flattened_features)):\n",
    "            print(f\"Warning: NaN values found in {paper_path}. Replacing with 0.\")\n",
    "            for i in range(len(flattened_features)):  # Handle NaNs with a loop\n",
    "                if np.isnan(flattened_features[i]):\n",
    "                    flattened_features[i] = 0\n",
    "\n",
    "        # Append data as a dictionary with paper ID and features\n",
    "        papers_data.append({\n",
    "            \"paper_id\": paper_id,\n",
    "            \"features\": flattened_features\n",
    "        })\n",
    "\n",
    "# Extract `features` for model input\n",
    "X_predict = np.array([paper[\"features\"] for paper in papers_data])\n",
    "\n",
    "# Display the paper ID and first 500 characters of features from the first paper\n",
    "print(f\"Paper ID: {papers_data[0]['paper_id']}\")\n",
    "print(f\"First 500 features: {papers_data[0]['features'][:500]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbUeBR5ekBhW"
   },
   "source": [
    "EXTRACTING REFERENCE PAPERS ALONG WITH LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKeZncPWxfOf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Function to get texts and labels from the 'References' folder\n",
    "def extract_data_from_references(references_path):\n",
    "    features_list = []\n",
    "    labels = []\n",
    "\n",
    "    # Traverse the 'publishable' folder and assign label 1 (Publishable)\n",
    "    publishable_folder = os.path.join(references_path, 'Publishable')\n",
    "    for category in os.listdir(publishable_folder):\n",
    "        category_folder = os.path.join(publishable_folder, category)\n",
    "        if os.path.isdir(category_folder):\n",
    "            for paper in os.listdir(category_folder):\n",
    "                if paper.endswith('.pdf'):\n",
    "                    pdf_path = os.path.join(category_folder, paper)\n",
    "                    features_dict = extract_features(pdf_path)\n",
    "                    flattened_features = flatten_features(features_dict)\n",
    "\n",
    "                    # Convert flattened_features to a NumPy array of floats\n",
    "                    flattened_features = np.array(flattened_features, dtype=np.float32)\n",
    "\n",
    "                    # Replace NaN values with 0 or a specified value\n",
    "                    if np.any(np.isnan(flattened_features)):\n",
    "                        print(f\"Warning: NaN values found in {pdf_path}. Replacing with 0.\")\n",
    "                        flattened_features = np.nan_to_num(flattened_features, nan=0)\n",
    "\n",
    "                    features_list.append(flattened_features)\n",
    "                    labels.append(1)  # Label 1 for publishable papers\n",
    "\n",
    "    # Traverse the 'non_publishable' folder and assign label 0 (Non-Publishable)\n",
    "    non_publishable_folder = os.path.join(references_path, 'Non-Publishable')\n",
    "    for paper in os.listdir(non_publishable_folder):\n",
    "        if paper.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(non_publishable_folder, paper)\n",
    "            features_dict = extract_features(pdf_path)\n",
    "            flattened_features = flatten_features(features_dict)\n",
    "\n",
    "            # Convert flattened_features to a NumPy array of floats\n",
    "            flattened_features = np.array(flattened_features, dtype=np.float32)\n",
    "\n",
    "            # Replace NaN values with 0 or a specified value\n",
    "            if np.any(np.isnan(flattened_features)):\n",
    "                print(f\"Warning: NaN values found in {pdf_path}. Replacing with 0.\")\n",
    "                flattened_features = np.nan_to_num(flattened_features, nan=0)\n",
    "\n",
    "            features_list.append(flattened_features)\n",
    "            labels.append(0)  # Label 0 for non-publishable papers\n",
    "\n",
    "    return features_list, labels\n",
    "\n",
    "\n",
    "# Extract texts and labels from the references folder\n",
    "features_list, labels = extract_data_from_references(references_path)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Print the first few entries to check\n",
    "print(\"Texts and Labels for Training:\")\n",
    "print(features_list[:2])  # First 2 features (for example)\n",
    "print(labels[:2])  # Corresponding labels for the first 2 papers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93CCwUrX7XKt"
   },
   "source": [
    "DIVIDING THE EXTRACTED FEATURES LIST INTO TRAINING AND TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edg8A51xx4Ux"
   },
   "outputs": [],
   "source": [
    "X = np.array(features_list)\n",
    "y = np.array(labels)\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# Print shapes of the resulting sets to verify\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {len(y_train)}\")\n",
    "print(f\"Shape of y_test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWo9KXER81oA"
   },
   "source": [
    "TRAINING A FEED-FORWARD NEURAL NETWORK USING MODEL-AGNOSTIC META-LEARNING (MAML) TO ADAPT QUICKLY TO NEW TASKS, WHERE THE MODEL IS UPDATED USING TASK-SPECIFIC DATA, FOLLOWED BY META-GRADIENT UPDATES TO OPTIMIZE THE MODEL'S GENERALIZATION ABILITY ON UNSEEN TASKS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYvMWw791uy2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import higher\n",
    "\n",
    "# Define a simple feed-forward neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(2315, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 2)  # Output layer for binary classification\n",
    "\n",
    "        # Dropout layers to prevent overfitting\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFcqgL3w1x0B"
   },
   "outputs": [],
   "source": [
    "def maml_update(model, X_batch, y_batch, lr=0.01):\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Forward pass through the model\n",
    "    outputs = model(X_batch)\n",
    "    loss = nn.CrossEntropyLoss()(outputs, y_batch)\n",
    "\n",
    "    # Backpropagation and gradient computation\n",
    "    loss.backward()\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.data -= lr * param.grad  # Parameter update step for MAML\n",
    "\n",
    "    return loss\n",
    "\n",
    "def meta_train(model, train_data, test_data, val_data, meta_lr=0.001, lr=0.01, num_steps=10):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=meta_lr)\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        # Adapt to the task using MAML update\n",
    "        meta_train_batch, meta_test_batch = train_data, test_data\n",
    "        maml_update(model, meta_train_batch[0], meta_train_batch[1], lr=lr)\n",
    "\n",
    "        # Test the adapted model on the test batch (meta-test)\n",
    "        test_outputs = model(meta_test_batch[0])\n",
    "        test_loss = nn.CrossEntropyLoss()(test_outputs, meta_test_batch[1])\n",
    "\n",
    "        # Meta-gradient update\n",
    "        optimizer.zero_grad()\n",
    "        test_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and display validation accuracy\n",
    "        with torch.no_grad():\n",
    "            # Assuming val_data is a tuple (X_val, y_val)\n",
    "            val_outputs = model(val_data[0])  # Forward pass on validation set\n",
    "            val_predictions = torch.argmax(val_outputs, dim=1)  # Get the predicted class\n",
    "            val_accuracy = (val_predictions == val_data[1]).float().mean().item()  # Calculate accuracy\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Step {step + 1}/{num_steps} - Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpcZZZ1M_OSk"
   },
   "source": [
    "TRAINING AND TESTING THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PH8-7X9T16dJ"
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Meta-train with MAML (Make sure meta_train is correctly implemented)\n",
    "train_data = (torch.tensor(X_train[:1]), torch.tensor(y_train[:1]))  # Small subset for task-based learning\n",
    "test_data = (torch.tensor(X_test[:2]), torch.tensor(y_test[:2]))\n",
    "val_data = (torch.tensor(X_test[2:]), torch.tensor(y_test[2:]))\n",
    "\n",
    "# Perform meta-training with MAML (Ensure proper evaluation is inside meta_train)\n",
    "modell = meta_train(model, train_data, test_data,val_data, meta_lr=0.001, lr=0.01, num_steps=30)\n",
    "\n",
    "#  Replace NaN values\n",
    "X_train[np.isnan(X_train)] = 0\n",
    "X_test[np.isnan(X_test)] = 0\n",
    "\n",
    "# Alternative: Replace NaNs with column means\n",
    "col_means = np.nanmean(X_train, axis=0)\n",
    "inds = np.where(np.isnan(X_train))\n",
    "X_train[inds] = np.take(col_means, inds[1])\n",
    "\n",
    "inds_test = np.where(np.isnan(X_test))\n",
    "X_test[inds_test] = np.take(col_means, inds_test[1])\n",
    "\n",
    "# Evaluate MAML model directly on X_test\n",
    "with torch.no_grad():\n",
    "    maml_predictions = modell(torch.tensor(X_test, dtype=torch.float32))\n",
    "    maml_predictions = torch.argmax(maml_predictions, dim=1).numpy()  # Convert to numpy array\n",
    "\n",
    "# Calculate accuracy for MAML\n",
    "maml_accuracy = accuracy_score(y_test, maml_predictions)\n",
    "\n",
    "# Train other classifiers for comparison\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "log_reg_classifier = LogisticRegression(max_iter=1000)\n",
    "log_reg_classifier.fit(X_train, y_train)\n",
    "log_reg_predictions = log_reg_classifier.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate all classifiers\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "log_reg_accuracy = accuracy_score(y_test, log_reg_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"MAML Model Accuracy: {maml_accuracy}\")\n",
    "print(f\"SVM Accuracy: {svm_accuracy}\")\n",
    "print(f\"Logistic Regression Accuracy: {log_reg_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1AR-6t0BEFX"
   },
   "source": [
    "CONSIDERING MAML MODEL AS IT PERFORMED WELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDX4UIDADUdX"
   },
   "outputs": [],
   "source": [
    "# Initialize counters for model's prediction of class 1\n",
    "c1 = 0\n",
    "# Iterate through each prediction sample\n",
    "for idx, x in enumerate(X_predict):\n",
    "    x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0)  # Add batch dimension for MAML model\n",
    "\n",
    "    # Perform prediction with MAML model\n",
    "    with torch.no_grad():\n",
    "        maml_output = modell(x_tensor)\n",
    "        maml_pred = torch.argmax(maml_output, dim=1).item()  # Get the predicted class as an integer\n",
    "    if maml_pred == 1:\n",
    "        c1 += 1\n",
    "\n",
    "    # Print the predictions for this sample\n",
    "    print(f\"Sample {papers_data[i]['paper_id']}: MAML={maml_pred}\")\n",
    "\n",
    "# Print the total counts for class 1 predictions\n",
    "print(f\"\\nSummary of predictions for class 1:\")\n",
    "print(f\"MAML: {c1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQhIANOABLhn"
   },
   "source": [
    "-----------------------------------------------**TASK 2**--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_FmFqcNBXSB"
   },
   "source": [
    "ARRANGING ALL THE REFRENCE PAPER ACCORDING TO THE CONFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "re-XulSI4xE0"
   },
   "outputs": [],
   "source": [
    "conferences = [\n",
    "      {\n",
    "          'name': 'TMLR',\n",
    "          'reference_papers': [\n",
    "              {'file_name': 'TMLR_paper1.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/KDSH_2025_Dataset/Reference/Publishable/TMLR/R014.pdf'},\n",
    "              {'file_name': 'TMLR_paper2.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/KDSH_2025_Dataset/Reference/Publishable/TMLR/R015.pdf'}\n",
    "          ]\n",
    "      },\n",
    "      {\n",
    "          'name': 'NeurIPS',\n",
    "          'reference_papers': [\n",
    "              {'file_name': 'NeurIPS_paper1.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/KDSH_2025_Dataset/Reference/Publishable/NeurIPS/R012.pdf'},\n",
    "              {'file_name': 'NeurIPS_paper2.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/KDSH_2025_Dataset/Reference/Publishable/NeurIPS/R013.pdf'}\n",
    "          ]\n",
    "      },\n",
    "      {\n",
    "          'name': 'KDD',\n",
    "          'reference_papers': [\n",
    "              {'file_name': 'KDD_paper1.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/KDSH_2025_Dataset/Reference/Publishable/KDD/R010.pdf'},\n",
    "              {'file_name': 'KDD_paper2.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/KDSH_2025_Dataset/Reference/Publishable/KDD/R011.pdf'}\n",
    "          ]\n",
    "      },\n",
    "      {\n",
    "          'name': 'EMNLP',\n",
    "          'reference_papers': [\n",
    "              {'file_name': 'EMNLP_paper1.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/KDSH_2025_Dataset/Reference/Publishable/EMNLP/R008.pdf'},\n",
    "              {'file_name': 'EMNLP_paper2.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/KDSH_2025_Dataset/Reference/Publishable/EMNLP/R009.pdf'}\n",
    "          ]\n",
    "      },\n",
    "      {\n",
    "          'name': 'CVPR',\n",
    "          'reference_papers': [\n",
    "              {'file_name': 'CVPR_paper1.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/KDSH_2025_Dataset/Reference/Publishable/CVPR/R006.pdf'},\n",
    "              {'file_name': 'CVPR_paper2.pdf', 'file_path': '/content/drive/MyDrive/Colab Notebooks/KDSH_2025_Dataset/Reference/Publishable/CVPR/R007.pdf'}\n",
    "          ]\n",
    "      }\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WM4DhYsOBnH0"
   },
   "source": [
    "INTIALIZING WITH THE HUGGINGFACE API TOKEN\n",
    "\n",
    "not sharing the token along with code to keep it private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsqjs65_V_1C"
   },
   "outputs": [],
   "source": [
    "HUGGINGFACE_API_TOKEN = \"....API TOKEN.....\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0OibdWhEC3y"
   },
   "source": [
    "SEVERAL OPERATIONS TO LEARN PREDICT THE CONFERENCE ALONG WITH RATIONALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3_7sOySa3lI"
   },
   "outputs": [],
   "source": [
    "#Initializing important urls\n",
    "SUMMARIZATION_MODEL_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
    "EMBEDDING_MODEL_URL = \"https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2\"\n",
    "TEXT_GENERATION_MODEL_URL = \"https://api-inference.huggingface.co/models/EleutherAI/gpt-neo-2.7B\"\n",
    "headers = {\"Authorization\": f\"Bearer {HUGGINGFACE_API_TOKEN}\"}\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "MAX_TOKENS = 512\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def extract_structured_text(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract structured text from a PDF.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    structured_content = []\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        # Extract text as dictionary with more structured details\n",
    "        text = page.get_text(\"dict\")\n",
    "\n",
    "        structured_content.append(text)\n",
    "    return structured_content\n",
    "\n",
    "def extract_and_flatten_text(structured_content):\n",
    "    \"\"\"\n",
    "    Extract and flatten text content from structured content dictionaries.\n",
    "    \"\"\"\n",
    "    extracted_text = []\n",
    "    try:\n",
    "        for page in structured_content:\n",
    "            if 'blocks' in page:\n",
    "                print(f\"Processing page with {len(page['blocks'])} blocks.\")  # Debug: Check number of blocks\n",
    "                for block in page['blocks']:\n",
    "                    if 'lines' in block:\n",
    "                        print(f\"Processing block with {len(block['lines'])} lines.\")  # Debug: Check number of lines in each block\n",
    "                        for line in block['lines']:\n",
    "                            for span in line.get('spans', []):\n",
    "                                text = span.get('text', '').strip()\n",
    "                                if text:\n",
    "                                    extracted_text.append(text)\n",
    "            else:\n",
    "                print(\"No blocks found on this page.\")  # Debug: Check if blocks exist\n",
    "    except Exception as e:\n",
    "        print(f\"Error during text extraction: {e}\")\n",
    "    print(extracted_text[0])\n",
    "    return \" \".join(extracted_text)  # Combine all text into a single string\n",
    "\n",
    "def clean_text(content):\n",
    "    \"\"\"\n",
    "    Clean the extracted text by removing extra spaces and non-ASCII characters.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(content, str):\n",
    "            return ' '.join(content.split()).encode('ascii', 'ignore').decode('utf-8')\n",
    "        else:\n",
    "            raise ValueError(\"Input content is not a valid string.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during text cleaning: {e}\")\n",
    "        return \"\"\n",
    "def split_text_into_chunks(text, max_token_length=1024):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=False, padding=False)\n",
    "    tokenized_text = tokens['input_ids'][0]\n",
    "    print(f\"len of tokenized text{len(tokenized_text)}\")\n",
    "    chunks = []\n",
    "\n",
    "    # Split text into chunks of max_token_length tokens\n",
    "    for i in range(0, len(tokenized_text), max_token_length):\n",
    "        print(i)\n",
    "        chunk = tokenized_text[i:i + max_token_length]\n",
    "        chunks.append(tokenizer.decode(chunk, skip_special_tokens=True))\n",
    "\n",
    "    return chunks\n",
    "def summarize_content(content):\n",
    "    \"\"\"\n",
    "    Summarize the given content using an external summarization API.\n",
    "    \"\"\"\n",
    "    content = clean_text(content)\n",
    "    print(f\"the content..........{content[:50]}\")\n",
    "    print(len(content))  # Ensure the content is cleaned\n",
    "    if not content:\n",
    "        print(\"Empty content after cleaning. Skipping summarization.\")\n",
    "        return None\n",
    "\n",
    "    extracted_text = content\n",
    "\n",
    "    # Split the extracted text into chunks\n",
    "    chunks = split_text_into_chunks(extracted_text)\n",
    "    print(f\"len of chunks{len(chunks)}\")\n",
    "    # Summarize each chunk\n",
    "    summarized_text = \"\"\n",
    "    i=0\n",
    "    for chunk in chunks:\n",
    "        print(f\"Processing chunk {i}\")\n",
    "        print(chunk)\n",
    "        print(type(chunk))\n",
    "        i+=1\n",
    "        try:\n",
    "            payload = {\"inputs\": chunk}\n",
    "            response = requests.post(SUMMARIZATION_MODEL_URL, headers=headers, json=payload)\n",
    "            response.raise_for_status()  # Raise an error for non-200 status codes\n",
    "            result = response.json()\n",
    "            if isinstance(result, dict) and \"error\" in result:\n",
    "                raise ValueError(f\"Summarization API Error: {result['error']}\")\n",
    "            summarized_text +=result[0][\"summary_text\"]+\" \"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request error: {e}\")\n",
    "        except ValueError as ve:\n",
    "            print(ve)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error during summarization: {e}\")\n",
    "    return summarized_text\n",
    "\n",
    "def process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Process a PDF file: extract, clean, and summarize text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        structured_content = extract_structured_text(pdf_path)  # Step 1: Extract structured content\n",
    "        print(f\"Structured content extracted: {structured_content[:1]}\")  # Debug: Print a sample\n",
    "\n",
    "        flat_text = extract_and_flatten_text(structured_content)  # Step 2: Flatten text\n",
    "        if not flat_text:\n",
    "            print(\"No text extracted from the PDF.\")\n",
    "            return None\n",
    "        print(f\"Type of flat_text: {type(flat_text)}\")\n",
    "        print(f\"First 100 characters of flat_text: {flat_text[:100]}\")\n",
    "        summary = summarize_content(flat_text)  # Step 3: Summarize content\n",
    "        if summary:\n",
    "            print(f\"Summary generated: {summary[:100]}...\")  # Debug: Print the first 100 characters\n",
    "        else:\n",
    "            print(\"Summary could not be generated.\")\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error during PDF processing: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_embedding_from_local_model(text):\n",
    "    \"\"\"\n",
    "    Get the embedding for the text using the local SentenceTransformer model.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    # Get the embedding for the text\n",
    "    print(type(model))\n",
    "    embedding = model.encode(text)\n",
    "    return np.array(embedding)\n",
    "\n",
    "\n",
    "def get_text_embeddings(text, max_chunk_size=384):\n",
    "    \"\"\"\n",
    "    Split the text into chunks, get embeddings via API, and combine them.\n",
    "    \"\"\"\n",
    "    # Tokenize the text into chunks\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + max_chunk_size]) for i in range(0, len(words), max_chunk_size)]\n",
    "\n",
    "    chunk_embeddings = []\n",
    "    print(len(chunks))\n",
    "    i=0\n",
    "    for chunk in chunks:\n",
    "      print(f\"Processing chunk {i}\")\n",
    "      i+=1\n",
    "      # Get embedding for each chunk via API\n",
    "      embedding = get_embedding_from_local_model(chunk)\n",
    "      chunk_embeddings.append(embedding)\n",
    "\n",
    "    # Combine all chunk embeddings using mean pooling\n",
    "    combined_embedding = np.mean(chunk_embeddings, axis=0)\n",
    "    return combined_embedding\n",
    "\n",
    "# Debugging: Ensure proper inputs to clean_text and summarize_content\n",
    "def debug_inputs(conferences):\n",
    "    for i, conference in enumerate(conferences):\n",
    "        if not isinstance(conference, str):\n",
    "            print(f\"Debug: Non-string content at index {i}: {conference}\")\n",
    "# Train profiles for conferences\n",
    "def create_conference_profiles(conferences):\n",
    "    profiles = {}\n",
    "    i=0\n",
    "    for conference in conferences:\n",
    "        print(f\"...................{i}....................\")#for verifying the process\n",
    "        i+=1\n",
    "        print(f\"Processing conference: {conference['name']}\")\n",
    "        embeddings = []\n",
    "        for paper in conference['reference_papers']:\n",
    "            # structured_text = extract_structured_text(paper['file_path'])\n",
    "            summarized_text = process_pdf(paper['file_path'])\n",
    "            embeddings.append(get_text_embeddings(summarized_text))\n",
    "        profiles[conference['name']] = np.mean(embeddings, axis=0)\n",
    "    return profiles\n",
    "\n",
    "# Classify a test paper\n",
    "def classify_test_paper(test_paper_path, conference_profiles):\n",
    "    #structured_text = extract_structured_text(test_paper_path)\n",
    "    summarized_text = process_pdf(test_paper_path)\n",
    "    test_embedding = get_text_embeddings(summarized_text)\n",
    "\n",
    "    scores = {}\n",
    "    for conference, profile_embedding in conference_profiles.items():\n",
    "        scores[conference] = cosine_similarity([test_embedding], [profile_embedding])[0][0]\n",
    "    return sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def generate_justification(test_paper, best_conference, similarity_score):\n",
    "    \"\"\"\n",
    "    Generates a detailed and concise justification for the classification of a paper to a conference.\n",
    "\n",
    "    Parameters:\n",
    "        test_paper (str): The content of the test paper.\n",
    "        best_conference (str): The classified conference name.\n",
    "        similarity_score (float): The similarity score for the classification.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated justification.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"The paper is classified under the {best_conference} conference based on a similarity score of {similarity_score:.2f}. \"\n",
    "        f\"Analyze the paperâ€™s content, methodology, and findings, and provide a concise rationale (up to 100 words) explaining \"\n",
    "        f\"how it aligns with the themes, focus areas, and quality standards of the {best_conference} conference.\"\n",
    "    )\n",
    "    payload = {\"inputs\": prompt}\n",
    "\n",
    "    # Make a POST request to the Hugging Face text generation API\n",
    "    response = requests.post(TEXT_GENERATION_MODEL_URL, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            # Extract and return the generated text\n",
    "            generated_text = response.json()[0][\"generated_text\"]\n",
    "            generated_text = generated_text[len(prompt):].strip()\n",
    "            # Limit to 100 words if the model generates more\n",
    "            word_limit = 100\n",
    "            truncated_text = \" \".join(generated_text.split()[:word_limit])\n",
    "            return truncated_text\n",
    "        except (KeyError, IndexError) as e:\n",
    "            raise ValueError(f\"Unexpected response structure: {response.json()}\") from e\n",
    "\n",
    "    # Raise an error if the response is not successful\n",
    "    raise ValueError(f\"Error in text generation API: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21jlLN1DFDe9"
   },
   "source": [
    "INTIALIZING CONFERENCE PROFILE ALONG WITH PAPER IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AW1oOF-9g4ev"
   },
   "outputs": [],
   "source": [
    "#storing  paper id\n",
    "import time\n",
    "\n",
    "profiles = create_conference_profiles(conferences)\n",
    "print(\"-------CONFRENCE PROFILE COMPLETED----------\")\n",
    "paper_ids=[]\n",
    "for paper in papers_data:\n",
    "   paper_ids.append(paper[\"paper_id\"])\n",
    "# List to store results\n",
    "print(paper_ids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbkI3bL-FrFC"
   },
   "source": [
    "PREDICTING THE CONFRENCE ALONG WITH PREDICTING IF THE PAPER IS PUBLISHABLE OR NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFlChfNB2hmf"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "# Predict one by one and store the results\n",
    "for x in (X_predict):\n",
    "  print(f\"...................{i}....................\")\n",
    "  print(f\"Processing paper {paper_ids[i]}\")\n",
    "  x_tensor = torch.tensor(x, dtype=torch.float32)  # Add batch dimension for MAML model\n",
    "  with torch.no_grad():\n",
    "      maml_output = modell(x_tensor)\n",
    "      maml_pred = torch.argmax(maml_output, dim=0).numpy()\n",
    "  if(maml_pred==1):\n",
    "    test_paper_text=os.path.join(papers_path,papers_data[i]['paper_id']+\".pdf\" )\n",
    "    classification = classify_test_paper(test_paper_text, profiles)\n",
    "    best_conference, score = classification[0]\n",
    "    # Generate justification\n",
    "    justification = generate_justification(test_paper_text, best_conference, score)\n",
    "    print(f\"Paper ID: {paper_ids[i]}, MAML Prediction: {maml_pred}, Classified Conference: {best_conference}, Rationale: {justification}\")\n",
    "    results.append([paper_ids[i], maml_pred, best_conference,justification])\n",
    "  # Add result to the list\n",
    "  else:\n",
    "    results.append([paper_ids[i], maml_pred,\"na\",\"na\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVBw3TMWGjxK"
   },
   "source": [
    "SAVING THE RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Npg05SNw6ye3"
   },
   "outputs": [],
   "source": [
    "print(len(results))# to verify every test papers are iterated\n",
    "df = pd.DataFrame(results, columns=['Paper ID', 'Publishable','Conference','Rationale'])\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'predictions.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOGrfdqts/ePuDN9cM+QJcf",
   "provenance": [
    {
     "file_id": "1ipJGTaUaHObeYePbQGAq2ZvsV8c7vrZL",
     "timestamp": 1736792523896
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
